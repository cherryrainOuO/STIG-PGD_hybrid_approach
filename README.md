# Attacking Fake Image Detectors with STIG-PGD
## Description
### ðŸš€ Project Overview
This repository contains the official PyTorch implementation of the STIG-PGD method, a novel adversarial image transformation technique designed to neutralize state-of-the-art fake image detectors.

Our method uniquely combines Spectral Transformation for Image Generation (STIG) and Projected Gradient Descent (PGD) to create Refined Fake Images that evade detection systems focusing on both spectral artifacts and visual inconsistencies.

### Core Contributions
Hybrid Attack Superiority: Achieves a significantly higher attack success rate against fake image detectors compared to single-technique approaches.

Frequency-Selective Artifact Injection: Addresses the limitations of traditional PGD by applying adversarial artifacts selectively to the Low-Frequency (LF) spectrum while using STIG to refine the High-Frequency (HF) spectrum.

Novel Loss Function: Introduces a hybrid PGD loss that integrates the STIG framework's Reconstruction Loss, ensuring the generated artifacts complement spectral refinement.

Vulnerability Proof: Demonstrates the fragility of current fake image detection models, guiding future research toward more robust defense mechanisms.
## Performance Comparison
## Additional Results
## Requirements and Installation
## Getting Started
## Reference
## Team Introduction
| Name | Student ID | Major |
| :--- | :--- | :--- |
| **Hyeonjun Cha** | 202011378 | Computer Science and Engineering |
| **Euntaek Lee** | 201911203 | Computer Science and Engineering |
| **Kyeongbeom Park** | 202011291 | Computer Science and Engineering |

